---
title: "An introduction to Stan programming"
author: "Sean Anderson"
output:
  html_document:
    toc: true
    toc_float: true
---

```{r, echo=FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.width = 6,
  fig.asp = 0.618,
  fig.align = "center"
)
show_file = function(file) {
  cat(paste(readLines(file), collapse = "\n"))
}
```

```{r, warning=FALSE, message=FALSE}
library(tidyverse)
theme_set(theme_light())
```

```{r}
library(rstan)
```

```{r}
rstan_options(auto_write = TRUE)
```

```{r}
# options(mc.cores = parallel::detectCores())
```

Let's simulate some data to fit a very simple Stan model to. We will focus on a linear model with normally distributed errors.

```{r}
set.seed(42)
N <- 30
x <- rnorm(N, 0, 0.5)
alpha <- -0.2
beta <- 0.4
sigma <- 0.3
y <- rnorm(N, mean = alpha + x * beta, sd = sigma)
dat <- tibble(x = x, y = y)
```

```{r}
ggplot(dat, aes(x, y)) + geom_point()
```

```{r}
show_file("stan/lm.stan")
```

The first time we run the next code chunk, Stan will translate our model into C++ and compile it. This will take little while. After that, assuming we set `rstan_options(auto_write = TRUE)`, Stan will avoid recompiling the model and less something in the model code changes.

Let's sample from the model now:

```{r}
fit <- stan("stan/lm.stan", chains = 4, iter = 2000,
  data = list(x = dat$x, y = dat$y, N = length(dat$y)))
```

Congratulations --- you fit your first handwritten Stan model! We can do everything with the posterior samples that we could do with the samples from an rstanarm model or a brms model.

Some of the built-in helper functions and those packages won't work with our model though.

```{r}
fit
```

```{r}
pars <- c("alpha", "beta", "sigma")
print(fit, pars = pars)
```

```{r, eval=FALSE}
shinystan::launch_shinystan(fit)
```

```{r}
plot(fit, pars = pars)
```

Experiment with inspecting the posterior chains using the bayesplot package.

```{r}
fit_array <- as.array(fit)
bayesplot::mcmc_trace(fit_array, pars = pars) 
# exercise
```

Experiment with inspecting the posterior predictive distribution using the bayesplot package:

```{r}
pp <- extract(fit)$posterior_predictions
bayesplot::ppc_dens_overlay(y = dat$y, yrep = pp[1:25, ])
```

Let's say we want to extract linear model predictions from the posterior. We can do that with the existing samples in R or we could program that into the `generated quantities` section of our Stan model.

Let's start by doing it in R:

```{r}
post <- extract(fit)
```

The output from `rstan::extract()` is a named list. Each element of the list is a numeric vector of samples if that parameter had one dimension (as all of our parameters did this time), or a matrix of samples if, say, beta had represented multiple slope parameters. 

```{r}
names(post)
dim(post$beta)
```

There are a variety of more slick ways to do this, but I'm going to do it in the most simple explicit way possible so you can see what's happening.

<https://github.com/mjskay/tidybayes>

```{r}
N <- 100
ggplot(dat, aes(x, y)) + geom_point() +
  geom_abline(
    intercept = post$alpha[1:N], 
    slope = post$beta[1:N], 
    alpha = 0.2)
```

Is that starting to look like the confidence/credible intervals are used to looking at?

How would we derive posterior predictions? In other words, how would we add on the observation component to our predictions? Let's manually create 8 draws from the posterior predictive distribution and compare them to our data. 

```{r}
n_sim <- 8
out <- vector(mode = "list", length = 8)
for (i in seq_along(out)) {
  out[[i]] <- tibble(x = x)
  out[[i]]$i <- i
  out[[i]]$y_pp <- 
    rnorm(
      n = length(x), 
      mean = post$alpha[i] + post$beta[i] * x, 
      sd = post$sigma[i])
}
out <- dplyr::bind_rows(out) # turn the list into a data.frame
out$type <- "posterior prediction"

# add the real data as the last panel:
out <- dplyr::bind_rows(out, 
  tibble(x = x, y_pp = y, type = "observed", i = 9))

ggplot(out, aes(x, y_pp, colour = type)) + geom_point() + 
  facet_wrap(~i)
```

```{r}
log_lik <- loo::extract_log_lik(fit, merge_chains = FALSE)
rel_n_eff <- loo::relative_eff(exp(log_lik))
loo::loo(log_lik, r_eff = rel_n_eff)
```
